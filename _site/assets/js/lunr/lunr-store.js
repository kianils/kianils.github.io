var store = [{
        "title": "Comic Universe Graph",
        "excerpt":"Overview   A cloud-native knowledge graph that models comic universes (Marvel, DC, etc.) as a network of characters, issues, volumes, arcs, and events. Comic universes are inherently graph-shaped: characters appear in issues, team up, face villains, and participate in arcs and events. Modeling this as a graph enables powerful queries (paths, timelines, co-occurrence) that would be cumbersome with relational DBs—questions like “First meeting of Spider-Man and Wolverine?” or “Path between two characters via shared issues” become graph traversals.   Why recruiters care: Demonstrates graph databases, cloud architecture (Azure), API design, and full-stack development—skills directly applicable to recommendation systems, content graphs, and data platforms.   Key Features                  Feature       Description                       Graph Database       Azure Cosmos DB (Gremlin API) stores vertices (characters, issues, volumes, arcs, events, teams) and edges (APPEARS_IN, TEAMED_WITH, VILLAIN_OF, etc.)                 Path Finding       Shortest path between characters via shared issues/teams                 Timeline       Chronological list of issues/arcs/events for a character                 Issues in Common       Finds issues featuring multiple specified characters                 Search       Full-text search across characters, volumes, arcs                 Data Ingestion       Scripts for Comic Vine API and Marvel API; optional hand-curated JSON/CSV                 Interactive Frontend       Cytoscape.js / D3 / vis-network for graph visualization           How It Works      Data Ingestion: Python scripts fetch from Comic Vine and Marvel APIs; normalize to a common schema; insert vertices and edges via Gremlin.   Graph Queries: Azure Functions execute Gremlin traversals for path, timeline, search, and subgraph endpoints.   API Layer: HTTP-triggered Functions expose REST APIs (e.g., /api/path?from=Spider-Man&amp;to=Wolverine).   Frontend: Static Web App renders the graph; users search, pick characters, and view paths or timelines.   Technical Architecture   Graph Schema (Cosmos DB Gremlin)   Vertices: character, issue, volume, arc, event, team  Edges: APPEARS_IN, TEAMED_WITH, VILLAIN_OF, PART_OF_ARC, PART_OF_EVENT, IN_VOLUME, MEMBER_OF   API Design (Azure Functions)                  Method       Route       Description                       GET       /api/path       from, to → shortest path via shared issues/teams                 GET       /api/timeline       character → chronological issues/arcs/events                 GET       /api/issues-in-common       chars → issues featuring all                 GET       /api/search       q → search characters/volumes/arcs                 GET       /api/graph       ids, depth → subgraph for visualization                 GET       /api/character/{id}       Character details + adjacent nodes           Project Structure   comic_universe_graph/ ├── PLAN.md          # Architecture, schema, phases ├── data/            # Seed JSON, schema examples ├── scripts/         # ingest_comicvine.py, ingest_marvel.py, seed_from_json.py ├── api/             # Azure Functions (path, timeline, search, graph) └── web/             # Static Web App frontend (Cytoscape.js / D3)   Azure Resources      Cosmos DB — Gremlin API, graph container   Azure Functions — Python or Node.js, HTTP triggers   Static Web Apps — Frontend hosting   Key Vault — API keys (Comic Vine, Marvel), Cosmos connection   Managed Identity — Secure access to Key Vault and Cosmos (no keys in code)   Blob Storage (optional) — Cache API responses; respect rate limits   Example Gremlin Queries   // Character appears in issue g.V().has('character', 'id', 'cv-spider-man')   .addE('APPEARS_IN').to(g.V().has('issue', 'id', 'marvel-asymmetric-1'))   .property('role', 'hero')  // Shortest path between characters g.V().has('character', 'name', 'Spider-Man')   .repeat(both().simplePath())   .until(has('character', 'name', 'Wolverine'))   .path().limit(1)   Skills &amp; Technologies      Azure Cosmos DB — Gremlin API, graph modeling   Azure Functions — Serverless HTTP APIs   Gremlin — Graph traversal queries   Python — Ingest scripts, API logic   JavaScript — Cytoscape.js, D3, vis-network   REST API — Design, documentation   Repository   View on GitHub  ","categories": [],
        "tags": [],
        "url": "/cs-projects/Comic-Universe-Graph/",
        "teaser": null
      },{
        "title": "LLM Text Attribution & Temporal Style Tracker",
        "excerpt":"Overview   An LLM-powered tool that assesses whether text is human-written or AI-generated, and tracks how writing styles evolve over time. The system addresses a practical problem: distinguishing human-written from AI-generated text and tracking how authorship or style changes over multiple revisions. Uses prompt engineering to elicit reliable authenticity signals, feature extraction (sentence length, vocabulary richness) to quantify style, and threshold-based drift detection to flag meaningful changes without false positives.   Why recruiters care: Demonstrates full-stack development (Flask + React), prompt engineering, RAG integration, and handling of real-world NLP tasks with clear business value.   Key Features                  Feature       Description                       Authenticity Analysis       Uses optimized LLM prompts to assess whether text is human or AI-generated                 Version History Tracking       Stores multiple versions of documents with timestamps for longitudinal analysis                 Style Drift Detection       Identifies significant changes in writing patterns between versions (configurable thresholds)                 Timeline Visualization       Multi-panel graphs showing authenticity scores and style feature evolution over time                 REST API       Flask backend with endpoints for analyze, documents, versions, drift detection                 React Frontend       Modern UI with document tracking, analyzer, and dashboard components           How It Works      Single-Text Analysis: User submits text; system extracts style features (sentence length, lexical diversity, etc.) and runs LLM-based authenticity assessment.   Version Tracking: Multiple versions of the same document are stored with timestamps; each version is analyzed and metadata is persisted.   Drift Detection: Consecutive versions are compared to identify significant changes in style features and authenticity scores.   Visualization: Timeline graphs show authenticity score evolution, feature changes, and marked drift points.   Technical Architecture   Stack      Backend: Python, Flask, Flask-CORS   Frontend: React, Tailwind CSS   LLM: OpenAI API (prompt engineering, RAG)   Storage: JSON-based version history (extensible to DB)   API Endpoints      POST /api/analyze — Analyze a single text for authenticity   GET /api/documents — List all tracked documents   GET /api/documents/&lt;id&gt;/versions — Get version history   POST /api/drift — Detect style drift between versions   GET /api/health — Health check   Project Structure   ├── app.py                  # Flask API ├── temporal_tracker.py     # Core: version tracking, drift detection, LLM analysis ├── dataset_evaluator.py    # Dataset-level evaluation ├── frontend/               # React app │   └── src/ │       ├── components/     # Analyzer, Dashboard, DocumentTracker │       └── contexts/       # ThemeContext └── temporal_data/          # Persisted version history   Skills &amp; Technologies      Python — Backend logic, API design   Flask — REST API, CORS   OpenAI API — LLM integration, prompt engineering   RAG — Retrieval-Augmented Generation for context   NLP — Style feature extraction (lexical diversity, sentence structure)   React — Frontend, component architecture   Tailwind CSS — Styling   Repository   View on GitHub  ","categories": [],
        "tags": [],
        "url": "/cs-projects/LLM-Text-Attribution/",
        "teaser": null
      },{
        "title": "Movie Transcripts Lexical Analysis",
        "excerpt":"Overview   A research-oriented NLP project that explores how vocabulary in cinema evolves over time using the Movie Transcripts 59k Kaggle dataset. The project connects NLP techniques to film studies: vocabulary choices in scripts reflect genre, era, and authorial style. The Lexical Trie enables efficient computation at scale (59k movies), and the divergence visualization makes abstract lexical relationships interpretable.   Why recruiters care: Demonstrates algorithmic thinking, custom data structure design, NLP tooling (NLTK), and the ability to turn research ideas into working software with clear visualizations.   Key Features                  Feature       Description                       Lexical Trie       Custom prefix tree for efficient word storage, similarity computation, and vocabulary analysis                 Divergence Timeline       Interactive branching timeline showing how movie vocabularies diverge over time                 Similarity Metrics       Jaccard and Cosine similarity for clustering lexically similar movies                 Temporal Clustering       Groups movies by vocabulary + temporal proximity (within configurable year windows)                 Visualization       Static PNG and interactive HTML (Plotly) outputs                 Kaggle Integration       Uses Kaggle API / kagglehub for dataset loading           How It Works      Data Loading: Fetches Movie Transcripts 59k dataset (movie titles, transcripts, metadata).   Trie Construction: Builds a Lexical Trie from all transcript words; tracks word counts and which movies contain each word.   Lexical Profiles: Each movie gets a vocabulary profile from the trie.   Clustering: Movies are clustered by Jaccard/Cosine similarity and temporal proximity.   Divergence Tree: Constructs a tree structure showing where vocabulary branches diverge.   Visualization: Renders branching timeline (year on x-axis, divergence on y-axis) with color-coded clusters.   Technical Architecture   Lexical Trie (lexical_trie.py)      Insert: O(m) per word (m = word length)   Search / Prefix: O(m)   Similarity: Jaccard and Cosine computed from trie-derived word sets   Tracks word_count, movies per node for downstream analysis   Divergence Timeline (divergence_timeline.py)      Builds lexical profiles per movie   Configurable similarity_threshold and min_movies_per_cluster   Outputs: divergence_timeline.png, divergence_timeline.html, divergence_tree.json   Project Structure   ├── lexical_trie.py              # Trie data structure ├── divergence_timeline.py       # Main divergence pipeline ├── temporal_evolution_analysis.py  # Temporal language metrics ├── explore_dataset.py           # Dataset exploration └── requirements.txt             # NLTK, pandas, kagglehub, etc.   Algorithms   Jaccard Similarity  J(A, B) = |A ∩ B| / |A ∪ B|  Measures vocabulary overlap (0 = different, 1 = identical).   Cosine Similarity  Uses word frequencies from the trie; weighted by how common words are across movies.   Clustering     Temporal clustering: groups by lexical similarity + year proximity (e.g., 20-year window)   Divergence tree: connects clusters by similarity and time; splits represent vocabulary divergence events   Research Applications      Genre Evolution — Track how Action, Drama, Comedy vocabularies diverge over decades   Director Styles — Compare lexical fingerprints of different directors   Cultural Periods — Identify lexical shifts (e.g., tech terms in 2000s)   Innovation Tracking — Find movies with unusually high divergence (lexical innovators)   Skills &amp; Technologies      Python — Core logic, data processing   NLTK — Tokenization, stopwords, POS tagging   Pandas — Data handling   Kaggle — Dataset access (kagglehub)   Plotly — Interactive visualizations   Data Structures — Custom Trie implementation   Repository   View on GitHub  ","categories": [],
        "tags": [],
        "url": "/cs-projects/Movie-Transcripts-Lexical-Analysis/",
        "teaser": null
      },{
        "title": "Survivor Simulator",
        "excerpt":"Overview   Survivor Simulator is a full-stack web application that simulates the Survivor TV show using real contestant data from True Dork Times. The ML models use survivor-specific features: challenge performance, social connections, alliance membership, vote history, and morale. Training data comes from historical simulation runs, teaching the models which attribute combinations tend to lead to elimination vs. survival.   Project Details   Survivor Simulator lets fans explore different season outcomes, run fantasy simulations, and predict elimination results using machine learning models. The project demonstrates end-to-end software engineering: data fetching and processing, game logic, web interfaces, and educational ML implementations.   Key Features                  Feature       Description                       Data Fetching       Automatically fetches player data from True Dork Times for any season                 Player Initialization       Processes Excel data into players with realistic stats (challenge skill, intelligence, social skill, luck, morale)                 Tribe Management       Organize players into tribes with dynamic stats tracking                 Alliance System       Form and manage alliances based on social graphs and player relationships                 Challenge System       Run tribal and individual immunity challenges with outcome modeling                 Tribal Councils       Simulate voting with strategic decision-making from alliances and attributes                 Machine Learning       Perceptron and MLP models for predicting game outcomes                 Web Interface       Flask-based app with tribe sorter, simulation views, and API endpoints           How It Works      Data Collection: Fetches season data from True Dork Times and processes it into player stats (challenge skill, intelligence, social skill, luck).   Tribe Formation: Players are randomly divided into tribes; stats update as the game progresses.   Alliance Formation: Alliances form from social graphs and player compatibility.   Game Simulation:            Challenges determine immunity winners       Tribal councils determine vote-outs based on alliances and attributes       Player stats (morale, votes received) update dynamically           ML Prediction: Perceptron and MLP models predict vote-out risk and outcomes from player features.   Technical Architecture   Project Structure   SurvivorSimulator/ ├── app.py                      # Flask web application ├── game_engine.py              # Main game simulation engine ├── game_mechanics.py           # Core mechanics (challenges, voting) ├── alliance_sim.py             # Alliance formation algorithms ├── ml_models.py                # Perceptron &amp; MLP implementations ├── initializePlayers.py        # Player initialization from Excel ├── SurvivorData.py             # Data fetching from True Dork Times ├── class_Definitions/ │   ├── playerClass.py          # Player model │   ├── tribeClass.py           # Tribe model │   └── allianceClass.py        # Alliance model └── templates/                  # Flask HTML templates   API Endpoints      GET / — Homepage   POST /process_season — Process a season number and initialize players   GET /tribe_sorter/&lt;season_number&gt; — Tribe sorting interface   GET /simulate/&lt;season_number&gt; — Simulation interface   GET /api/simulate/&lt;season_number&gt; — Run full simulation (JSON)   GET /api/simulate_round/&lt;season_number&gt; — Run single round (JSON)   Machine Learning Models   The project includes educational implementations from scratch:   Perceptron      Single-layer neural network for binary classification   Learns via weight updates from prediction errors   Features: challenge skill, social skill, intelligence, morale   Used to predict vote-out risk   Multi-Layer Perceptron (MLP)      Deep network with hidden layers for non-linear patterns   Handles complex interactions between player attributes   High-level SurvivorPredictor interface for game outcome prediction   Usage   Run the Web App   python app.py   Navigate to http://localhost:5000.   Run Simulations Programmatically   from game_engine import run_simulation  results = run_simulation(season_number=32, num_tribes=2, max_rounds=20)   Skills &amp; Technologies      Python — Core logic, data processing, ML   Flask — Web framework, templates, API   Pandas — Data handling from Excel   NumPy — ML model computations   Machine Learning — Perceptron, MLP from scratch   Repository   View on GitHub  ","categories": [],
        "tags": [],
        "url": "/cs-projects/SurvivorSimulator/",
        "teaser": null
      },{
        "title": "Multi-Material Plier Print",
        "excerpt":"Project Overview   Details to be added.   Multi-Material Plier Print   This project explores multi-material 3D printing for functional tools. More information will be added soon.  ","categories": [],
        "tags": [],
        "url": "/portfolio/MultiMaterialPlierPrint/",
        "teaser": "/assets/img/Slide-2.png"
      },{
        "title": "Syringe Pump",
        "excerpt":"Project Overview   This DIY syringe pump project demonstrates precision fluid handling capabilities with flow rates ranging from 1 μL/min to 10 mL/min. The pump was designed and built as part of my digital fabrication minor coursework, showcasing both mechanical design and control system integration.   Technical Specifications      Flow Rate Range: 1 μL/min to 10 mL/min   Precision: High-accuracy microfluidics control   Control System: Programmable stepper motor control   Syringe Compatibility: Standard medical syringes   Build Method: 3D printed components with off-the-shelf hardware   Technical Drawings                                                                                                                                                                                                                                                  Technical drawings and dimensioned views.       Off-the-Shelf Components                  Component       Part Number/Description       Quantity                       Ball Bearing       F688ZZ-Flanged-Ball-Bearing v2       1                 Lead Screw Collar       Lock-Collar-Lead-Screw v5       1                 Stepper Motor       NEMA-17-Motor v1       1                 Flexible Coupling       FLEXIBLE COUPLER v2       1                 End Support       End-Support v8       1                 Mounting Bolt (5mm)       M5x8mm-Bolt v2       Multiple                 Mounting Bolt (3mm)       M3x6mm-Bolt v3       Multiple                 Linear Bearing       LM8UU-Linear-Bearing v2       2                 Mounting Bolt (3mm)       M3x10mm-Bolt v2       Multiple                 Linear Rod Collar       Lock-Collar-Linear-Rod v5       2                 Motor Mount       motor mounting plate v8       1                 Linear Rod       Linear-Rod-8mmx200mm v2       2           Arduino Code   The syringe pump is controlled by an Arduino microcontroller running custom code that manages stepper motor control, flow rate calculations, and LED status indicators.   Key Features:     Flow Rate Control: Programmable flow rates from 1 μL/min to 10 mL/min   LED Status Indicators: Green (running), Blue (stopped), Red (error)   Button Control: Simple on/off toggle functionality   Precision Control: Microstepping for accurate flow delivery   #include &lt;AccelStepper.h&gt;  // Pin definitions #define stepPin 3 // gray #define directionPin 2 // orange #define redLED 5 // red #define greenLED 6 // green #define blueLED 7 // blue #define onOffButton 10 // pink  // Stepper motor setup AccelStepper stepper(AccelStepper::DRIVER, stepPin, directionPin);  // Variables bool onOffPressed = false; // Tracks the state of the system (on/off) float flowRate = 0.5; // mL/min float syringeDiameter = 19; //20 mL syringe float syringeRadius = syringeDiameter / 2; const float leadScrewLead = 8.0; // Lead screw lead in mm/rev const float stepsPerRevolution = 200.0; // Steps per revolution const float microsteps = 16.0; // Microstepping factor float stepsPerSecond = 0.0; // Calculated steps per second float volumePerStep;  void setup() {   // Initialize pins   pinMode(redLED, OUTPUT);   pinMode(greenLED, OUTPUT);   pinMode(blueLED, OUTPUT);   pinMode(onOffButton, INPUT_PULLUP);      // Stepper motor setup   stepper.setMaxSpeed(1000); // Maximum speed   stepper.setAcceleration(500); // Acceleration      // Default LED status (blue for stopped)   updateLEDs(); }  void loop() {   float volumePerStep = (PI * pow(syringeRadius, 2) * leadScrewLead) /                         (stepsPerRevolution * microsteps * 1000);   stepsPerSecond = flowRate / volumePerStep / 60;      // Check and handle the on/off button state   static bool previousState = HIGH;   bool currentState = digitalRead(onOffButton);      if (previousState == HIGH &amp;&amp; currentState == LOW) {     onOffPressed = !onOffPressed; // Toggle state     updateLEDs(); // Update LED based on state   }   previousState = currentState;      // Control the motor based on the current state   if (onOffPressed) {     stepper.setSpeed(stepsPerSecond); // Set motor speed     stepper.runSpeed(); // Run the motor   } else {     stepper.stop(); // Stop the motor   } }  void updateLEDs() {   if (onOffPressed) {     // Green LED ON for \"ON\" state     digitalWrite(redLED, LOW);     digitalWrite(greenLED, HIGH);     digitalWrite(blueLED, LOW);   } else {     // Blue LED ON for \"OFF\" state     digitalWrite(redLED, LOW);     digitalWrite(greenLED, LOW);     digitalWrite(blueLED, HIGH);   } }   CAD Model      Your browser does not support embedded CAD models. View CAD Model    Design Features   The syringe pump incorporates several key design elements:      Precision lead screw mechanism for accurate linear motion   Stepper motor control for programmable flow rates   Robust 3D-printed frame and mounting system   User-friendly interface for flow rate adjustment   Compact design suitable for laboratory environments   Applications   This syringe pump is ideal for:     Microfluidics research   Precise chemical dispensing   Laboratory automation   Operating Instructions   The syringe pump should be operated by adhering to the following steps:           Ensure that the power supply is connected to the syringe pump. The LED light should be blue.            Place the syringe in the supports with the tip that outputs liquid at the far right end.            Adjust the flow rate in the Arduino code at line 18.            Input the size of syringe into the Arduino code at line 19.            To begin dispensing liquid from the syringe, press the red power button to be lowered. This is placed at the bottom left of the front panel of the enclosure. The LED light should be green during liquid dispense.            To pause the liquid dispense, press the power button again so it is raised. The LED light should show blue.            To continue dispensing the liquid, press the power button again so it stays lowered.            Once all liquid possible has been dispensed, the LED will turn red and the actuation will stop.       Final Assembly      ","categories": [],
        "tags": [],
        "url": "/portfolio/SyringePump/",
        "teaser": "/assets/img/Syringepumpphotos/Homepage.jpg"
      },]
